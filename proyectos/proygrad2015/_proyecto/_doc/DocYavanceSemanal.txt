

18\04

svg en doc 
indice figuras
leer paper German
investigacion instalacion videos de docker, docker-machine  , containers.
investigacion instalacion Mesos
investigacion instalacion Hadoop

Consultas
el paper sirve como trabajo relacionado ? (estado del arte?)



Por ejemplo sonbre la instalacion de hadoop sobre mesos

http://localhost:5050/

hadoop  ,
 instalacion segun https://www.packtpub.com/packtlib/book/Big-Data-and-Business-Intelligence/9781783288762/2/ch02lvl1sec22/Installing%20Hadoop%20on%20Mesos

paso 5 baje una version mas nueva
wget  http://archive.cloudera.com/cdh5/cdh/5/hadoop-2.6.0-cdh5.7.0.tar.gz

paso 6 cambie ruta , estadno dentro de carpeta hadoop , instalacion hadoopmesos y hadoop propiamiente bajo apache/hadoop
cp target/hadoop-mesos-*.jar hadoop-*/share/hadoop/common/lib

paso 7 no pude crear enlace , no existe bin  y si lo creo no me permite crear enlaces fuertes a dicrectorios ln –s bin-mapreduce1 bin

idem dentro de etc 

renombre las carpetas en vez de acceder por enlace , bin-mapreduce1 por bin , y en etc hadoop-mapreduce1 por hadoop , tambien los ejemplo q amrcan copmo opcionales , example-mapreduce1 por examples

agregue variables a home/gabriel/Facu/proyecto/apache/hadoop/hadoop-2.6.0-cdh5.7.0/bin/hadoop-deamons.sh

export HADOOP_HOME=/home/gabriel/Facu/proyecto/apache/hadoop/hadoop-2.6.0-cdh5.7.0
export MESOS_NATIVE_LIBRARY=/usr/local/lib/libmesos.so

borre enlace a mapreduce2 renombre mapreduce1 a mapreduce /home/gabriel/Facu/proyecto/apache/hadoop/hadoop-2.6.0-cdh5.7.0/share/hadoop

pendiente


Zookeeper
investigacion instalacion Marathon


Hadoop

sangreaurinegra/prueba

sudo docker build -t "sangreaurinegra/prueba:1.0" dockerGerman/

 ---> 5095a3627c7f
Removing intermediate container e2084d6e31d0
Successfully built 5095a3627c7f
-- ejemplo run bash
docker run -t -i sangreaurinegra/prueba:1.0 /bin/bash

para no usar sudo en docker
gabriel@HP:~$ sudo groupadd docker
[sudo] password for gabriel: 
groupadd: el grupo «docker» ya existe
gabriel@HP:~$ sudo usermod -aG docker gabriel


mesos
en build
sudo ./bin/mesos-master.sh --ip=127.0.0.1 --work_dir=/var/lib/mesos


http://localhost:5050/

hadoop  ,
 instalacion segun https://www.packtpub.com/packtlib/book/Big-Data-and-Business-Intelligence/9781783288762/2/ch02lvl1sec22/Installing%20Hadoop%20on%20Mesos

paso 5 baje una version mas nueva
wget  http://archive.cloudera.com/cdh5/cdh/5/hadoop-2.6.0-cdh5.7.0.tar.gz

paso 6 cambie ruta , estadno dentro de carpeta hadoop , instalacion hadoopmesos y hadoop propiamiente bajo apache/hadoop
cp target/hadoop-mesos-*.jar hadoop-*/share/hadoop/common/lib


paso 7 no pude crear enlace , no existe bin  y si lo creo no me permite crear enlaces fuertes a dicrectorios ln –s bin-mapreduce1 bin

idem dentro de etc 

renombre las carpetas en vez de acceder por enlace , bin-mapreduce1 por bin , y en etc hadoop-mapreduce1 por hadoop , tambien los ejemplo q amrcan copmo opcionales , example-mapreduce1 por examples

agregue variables a home/gabriel/Facu/proyecto/apache/hadoop/hadoop-2.6.0-cdh5.7.0/bin/hadoop-deamons.sh

export HADOOP_HOME=/home/gabriel/Facu/proyecto/apache/hadoop/hadoop-2.6.0-cdh5.7.0
export MESOS_NATIVE_LIBRARY=/usr/local/lib/libmesos.so

borre enlace a mapreduce2 renombre mapreduce1 a mapreduce /home/gabriel/Facu/proyecto/apache/hadoop/hadoop-2.6.0-cdh5.7.0/share/hadoop









12/03
inconvenite scon espacio ne disco , al copiar las imagens de disco 1 a hsf no hay suficiente espacio

problema scon safe mode hadoop



pruebas con menos datos

Task Id : attempt_1489451681986_0002_m_000000_1, Status : FAILED
Error: java.io.FileNotFoundException: File '/root/workingdir/j8vb7afmq_res.txt' does not exist

probar con esa imagen local  error
Task Id : attempt_1489451681986_0002_m_000000_1, Status : FAILED
Error: java.io.FileNotFoundException: File '/root/workingdir/j8vb7afmq_res.txt' does not exist

en cl.out

***** evaluar reducir igual con errores agregando un file con los datos del error o algo 




xdimsum,> ERROR: Attempt to access undefined local variable `s4'.

  "b1 = b1 && (s4 == "NONE" || s4 == "NONE") && (s5 == "NONE" || s5 ==  ..."
     line 29: home$rayocosmico2.cl
     called as: `rayocosmico2 ()'
xdimsum,>




//DOC formas y distintas herramientas para hdfs , viendo caso no tengo espacio para importar images
http://stackoverflow.com/questions/32794340/different-ways-to-import-files-into-hdfs

//
Posible mejora a futuro desarrollarlo en spark


14/04

//Montar HDF Externo , 
	- modificar conf hdfs ruta a donde guarda los datos locales
	- la ruta debe ser a carpeta correspondietne a docker volumen 
	-  creacion de variable de entorno para ubicar carpetas dentro del volumen correspondiente a cada nodo .

En caso del Slave luego de importar  74 M vemos como funciona como un datanode
74M	./current/BP-301518945-172.17.0.2-1462936623257/current/finalized
4.0K	./current/BP-301518945-172.17.0.2-1462936623257/current/rbw
74M	./current/BP-301518945-172.17.0.2-1462936623257/current
74M	./current/BP-301518945-172.17.0.2-1462936623257
74M	./current
74M	.


RUN mv /tmp/hdfs-site.xml $HADOOP_INSTALL/etc/hadoop/hdfs-site.xml 

con la version 2.6.4 no tengo soporte de Evn. en los archivos de conf  . por lo que opto por setearsa desde export haddopsOpts , este cambio no surge efecto en los slaves.

/Soporte a Imagenes descartadas
	
	En las pruebas con datos (datos1) surgió que existen imagenes que el script las descarta por diferentes temas , uno puede ser bateria baja al momento de capturar la imagen , para las casos descartados no genera resultados , por lo que al momento de intentar reducir el resultado vacio hay que tenerlo el cuenta .

// Docker multihilo
	Al momento de crear los nodos Docker podemos indicarle cuantos procesadores utilizar y cuales , de esta manera logramos una ejecucion concurrente puesto que todos nuestros nodos Docker se encuentran en un mismo host.
 	



Probar cambiar el bashrc de los slave 
export HADOOP_INSTALL=/usr/local/hadoop 
por 
export HADOOP_INSTALL=/rutaAVolumenMontado/$HOSTNAME
Descartado al no ejecutarse el bash no obtendria las variable cargadas en el caso de los slaves el bash no se ejecuta 
por tal motivo paso a instalar la version 2.8.0








Conection Refuse

2017-05-20 21:45:33,071 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2017-05-20 21:45:33,071 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.min.datanodes = 0
2017-05-20 21:45:33,071 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.extension     = 30000
2017-05-20 21:45:33,072 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Retry cache on namenode is enabled
2017-05-20 21:45:33,073 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2017-05-20 21:45:33,075 INFO org.apache.hadoop.util.GSet: Computing capacity for map NameNodeRetryCache
2017-05-20 21:45:33,075 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2017-05-20 21:45:33,075 INFO org.apache.hadoop.util.GSet: 0.029999999329447746% max memory 889 MB = 273.1 KB
2017-05-20 21:45:33,075 INFO org.apache.hadoop.util.GSet: capacity      = 2^15 = 32768 entries
2017-05-20 21:45:33,081 INFO org.apache.hadoop.hdfs.server.namenode.NNConf: ACLs enabled? false
2017-05-20 21:45:33,081 INFO org.apache.hadoop.hdfs.server.namenode.NNConf: XAttrs enabled? true
2017-05-20 21:45:33,081 INFO org.apache.hadoop.hdfs.server.namenode.NNConf: Maximum size of an xattr: 16384
2017-05-20 21:45:33,082 WARN org.apache.hadoop.hdfs.server.common.Storage: Storage directory /root/hdfs/namenode does not exist
2017-05-20 21:45:33,084 WARN org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Encountered exception loading fsimage
org.apache.hadoop.hdfs.server.common.InconsistentFSStateException: Directory /root/hdfs/namenode is in an inconsistent state: storage directory does not exist or is not accessible.
	at org.apache.hadoop.hdfs.server.namenode.FSImage.recoverStorageDirs(FSImage.java:314)
	at org.apache.hadoop.hdfs.server.namenode.FSImage.recoverTransitionRead(FSImage.java:202)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.loadFSImage(FSNamesystem.java:1022)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.loadFromDisk(FSNamesystem.java:741)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.loadNamesystem(NameNode.java:538)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.initialize(NameNode.java:597)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:764)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:748)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.createNameNode(NameNode.java:1441)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.main(NameNode.java:1507)
2017-05-20 21:45:33,089 INFO org.mortbay.log: Stopped HttpServer2$SelectChannelConnectorWithSafeStartup@0.0.0.0:50070
2017-05-20 21:45:33,189 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Stopping NameNode metrics system...
2017-05-20 21:45:33,190 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: NameNode metrics system stopped.
2017-05-20 21:45:33,190 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: NameNode metrics system shutdown complete.
2017-05-20 21:45:33,190 FATAL org.apache.hadoop.hdfs.server.namenode.NameNode: Failed to start namenode.
org.apache.hadoop.hdfs.server.common.InconsistentFSStateException: Directory /root/hdfs/namenode is in an inconsistent state: storage directory does not exist or is not accessible.
	at org.apache.hadoop.hdfs.server.namenode.FSImage.recoverStorageDirs(FSImage.java:314)
	at org.apache.hadoop.hdfs.server.namenode.FSImage.recoverTransitionRead(FSImage.java:202)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.loadFSImage(FSNamesystem.java:1022)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.loadFromDisk(FSNamesystem.java:741)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.loadNamesystem(NameNode.java:538)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.initialize(NameNode.java:597)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:764)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:748)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.createNameNode(NameNode.java:1441)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.main(NameNode.java:1507)
2017-05-20 21:45:33,194 INFO org.apache.hadoop.util.ExitUtil: Exiting with status 1
2017-05-20 21:45:33,197 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down NameNode at master.kiwenlau.com/172.17.0.2


